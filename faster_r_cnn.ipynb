{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1, 120, 120, 3), dtype=uint8, numpy=\narray([[[[ 27,  26,  27],\n         [ 33,  36,  46],\n         [ 18,  17,  28],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[109, 108, 105],\n         [ 35,  38,  42],\n         [ 18,  18,  22],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[ 98,  98,  93],\n         [ 38,  39,  37],\n         [  9,   9,   8],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        ...,\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  6,   6,   6],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  6,   6,   6],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  3,   3,   3],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]]]], dtype=uint8)>,) and kwargs: {} for signature: (**kwargs).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/FIshing_vessel/faster_r_cnn.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/faster_r_cnn.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m image_tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(image_tensor, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)  \u001b[39m# 배치 차원 추가 (배치 크기 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/faster_r_cnn.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# 예측 수행\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/faster_r_cnn.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m results \u001b[39m=\u001b[39m model(image_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/faster_r_cnn.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m result \u001b[39m=\u001b[39m {key: value\u001b[39m.\u001b[39mnumpy() \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/faster_r_cnn.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# 박스, 클래스, 점수 추출\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/saved_model/load.py:817\u001b[0m, in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_attribute\u001b[39m(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 817\u001b[0m   \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_type_utils.py:446\u001b[0m, in \u001b[0;36mbind_function_inputs\u001b[0;34m(args, kwargs, function_type, default_values)\u001b[0m\n\u001b[1;32m    442\u001b[0m   bound_arguments \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mbind_with_defaults(\n\u001b[1;32m    443\u001b[0m       args, sanitized_kwargs, default_values\n\u001b[1;32m    444\u001b[0m   )\n\u001b[1;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 446\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    447\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBinding inputs to tf.function failed due to `\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00msanitized_kwargs\u001b[39m}\u001b[39;00m\u001b[39m for signature:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mfunction_type\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m   ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39mreturn\u001b[39;00m bound_arguments\n",
      "\u001b[0;31mTypeError\u001b[0m: Binding inputs to tf.function failed due to `too many positional arguments`. Received args: (<tf.Tensor: shape=(1, 120, 120, 3), dtype=uint8, numpy=\narray([[[[ 27,  26,  27],\n         [ 33,  36,  46],\n         [ 18,  17,  28],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[109, 108, 105],\n         [ 35,  38,  42],\n         [ 18,  18,  22],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[ 98,  98,  93],\n         [ 38,  39,  37],\n         [  9,   9,   8],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        ...,\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  6,   6,   6],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  6,   6,   6],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]],\n\n        [[  1,   1,   1],\n         [  1,   1,   1],\n         [  3,   3,   3],\n         ...,\n         [  1,   1,   1],\n         [  1,   1,   1],\n         [  1,   1,   1]]]], dtype=uint8)>,) and kwargs: {} for signature: (**kwargs)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # GPU 메모리를 필요할 때만 할당\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Faster R-CNN 모델 로드\n",
    "model = hub.load(\"https://www.kaggle.com/models/rishitdagli/faster-rcnn-cppe5/TensorFlow2/faster-rcnn-cppe5/1\")\n",
    "# 이미지 디렉토리 경로 설정 (테스트 이미지들이 있는 폴더)\n",
    "image_dir = '/home/elicer/FIshing_vessel/imgdata'  # 이 부분을 실제 이미지 폴더 경로로 수정하세요\n",
    "\n",
    "# 이미지 파일들 반복 처리\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):  # 확장자 필터링\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "        # 이미지 불러오기 및 전처리\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB로 변환\n",
    "\n",
    "        # 여기에서 이미지 크기를 조절합니다.\n",
    "        image_resized = cv2.resize(image_rgb, (120, 120))  # 입력 이미지를 더 작은 크기로 줄임 (예: (200, 200))\n",
    "\n",
    "        # 모델 입력을 위한 텐서로 변환\n",
    "        image_tensor = tf.convert_to_tensor(image_resized, dtype=tf.uint8)\n",
    "\n",
    "        # 배치 차원 추가 (배치 크기 = 1로 설정)\n",
    "        image_tensor = tf.expand_dims(image_tensor, axis=0)  # 배치 차원 추가 (배치 크기 1)\n",
    "\n",
    "        # 예측 수행\n",
    "        results = model(image_tensor)\n",
    "        result = {key: value.numpy() for key, value in results.items()}\n",
    "\n",
    "        # 박스, 클래스, 점수 추출\n",
    "        boxes = result[\"detection_boxes\"][0]  # [ymin, xmin, ymax, xmax]\n",
    "        classes = result[\"detection_classes\"][0].astype(np.int32)\n",
    "        scores = result[\"detection_scores\"][0]\n",
    "\n",
    "        # 예측 결과 시각화\n",
    "        height, width, _ = image_rgb.shape\n",
    "        for i in range(len(scores)):\n",
    "            if scores[i] > 0.5:  # 신뢰도 50% 이상만 표시\n",
    "                ymin, xmin, ymax, xmax = boxes[i]\n",
    "                start_point = (int(xmin * width), int(ymin * height))\n",
    "                end_point = (int(xmax * width), int(ymax * height))\n",
    "                color = (0, 255, 0)  # 초록색\n",
    "                thickness = 2\n",
    "                cv2.rectangle(image_rgb, start_point, end_point, color, thickness)\n",
    "\n",
    "                # 클래스 정보 표시\n",
    "                label = f\"Class {classes[i]}, Score: {scores[i]:.2f}\"\n",
    "                cv2.putText(image_rgb, label, (start_point[0], start_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # 결과 이미지 시각화\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(f\"Results for {filename}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
