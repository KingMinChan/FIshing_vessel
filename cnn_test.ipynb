{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 06:29:13.140588: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 06:29:13.153734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 06:29:13.171475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 06:29:13.176840: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 06:29:13.191376: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 06:29:14.364724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from six.moves.urllib.request import urlopen\n",
    "from six import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageOps\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.grid(False)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_on_image(image, ymin, xmin, ymax,\n",
    "                               xmax, color, font, thickness = 4,\n",
    "                               display_str_list = ()):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right,top), (left,top)],width = thickness, fill = color)\n",
    "\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = bottom + total_display_str_height\n",
    "    \n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
    "                        (left + text_width, text_bottom)],\n",
    "                        fill = color)\n",
    "        draw.text((left+margin, text_bottom - text_height - margin),\n",
    "                  display_str, fill = 'black', font = font)\n",
    "        text_bottom -= text_height - 2 * margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image, boxes, class_names, scores, max_boxes = 10, min_score = 0.1):\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype('arial.ttf',25)\n",
    "    except IOError:\n",
    "        print('Font not found, using default font.')\n",
    "        font = ImageFont.load_default()\n",
    "        \n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            display_str = '{}: {}%'.forma(class_names[i].decode('ascii'),\n",
    "                                          int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i] % len(colors))]\n",
    "            image_pil = Image.fromarray(np.unit8(image)).convert('RGB')\n",
    "            draw_bounding_box_on_image(\n",
    "                image_pil, ymin, xmin,\n",
    "                ymax, xmax, color,\n",
    "                font, display_str_list = [display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "2024-10-16 06:39:07.875577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38716 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 3g.40gb, pci bus id: 0000:e3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "module_handle = 'http://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2'\n",
    "\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "    img = load_img(path)\n",
    "\n",
    "    converted_img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time= time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "\n",
    "    result = {key:value.numpy() for key, value in result.items()}\n",
    "    print('이미지에서 찾은 %d개의 객체' %len(result['detection_scores']))\n",
    "    print('추론한 시간: ', end_time - start_time)\n",
    "\n",
    "    image_with_boxes = draw_boxes(\n",
    "        img.numpy(),result['detection_boxes'],\n",
    "        result['detection_class_entitles'], result['detection_scores']\n",
    "    )\n",
    "\n",
    "    display_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
