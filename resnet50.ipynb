{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>선종</th>\n",
       "      <th>상태</th>\n",
       "      <th>state</th>\n",
       "      <th>vessel_type</th>\n",
       "      <th>nation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>낚시어선</td>\n",
       "      <td>이동</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>낚시어선</td>\n",
       "      <td>조업</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>낚시어선</td>\n",
       "      <td>표류</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>등광조망</td>\n",
       "      <td>이동</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>등광조망</td>\n",
       "      <td>표류</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1576</td>\n",
       "      <td>범장망</td>\n",
       "      <td>이동</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1577</td>\n",
       "      <td>범장망</td>\n",
       "      <td>표류</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1578</td>\n",
       "      <td>유망</td>\n",
       "      <td>표류</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>1579</td>\n",
       "      <td>타망</td>\n",
       "      <td>조업</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>1580</td>\n",
       "      <td>타망</td>\n",
       "      <td>표류</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1581 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    선종  상태  state  vessel_type  nation_type\n",
       "0              0  낚시어선  이동      1            8            1\n",
       "1              1  낚시어선  조업      0            8            1\n",
       "2              2  낚시어선  표류      2            8            1\n",
       "3              3  등광조망  이동      1            2            0\n",
       "4              4  등광조망  표류      2            2            0\n",
       "...          ...   ...  ..    ...          ...          ...\n",
       "1576        1576   범장망  이동      1            3            0\n",
       "1577        1577   범장망  표류      2            3            0\n",
       "1578        1578    유망  표류      2            1            0\n",
       "1579        1579    타망  조업      0            0            0\n",
       "1580        1580    타망  표류      2            0            0\n",
       "\n",
       "[1581 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('preprocessed_whole_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# 이미지 디렉토리 경로\n",
    "image_dir = 'imgdata'  # 경로 수정 필요\n",
    "\n",
    "# 이미지 읽기 및 전처리\n",
    "images = []\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(('.jpg', '.png')):  # 여러 확장자를 처리\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB').resize((256, 256))  # 이미지 크기 조정 및 RGB 변환\n",
    "            image_array = img_to_array(image) / 255.0  # 정규화\n",
    "            images.append(image_array)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {filename}: {e}\")\n",
    "\n",
    "# 이미지 데이터를 NumPy 배열로 변환\n",
    "images = np.array(images)\n",
    "\n",
    "train_data = images\n",
    "train_data\n",
    "target = df['vessel_type']\n",
    "target = to_categorical(target, num_classes=10)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,851,274</span> (90.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,851,274\u001b[0m (90.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,798,154</span> (90.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,798,154\u001b[0m (90.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def ResNet50(input_shape=(256, 256, 3), num_classes=10):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # MobileNetV2 backbone\n",
    "    backbone = tf.keras.applications.ResNet50(input_shape=input_shape, include_top=False, weights='imagenet')(inputs)\n",
    "    \n",
    "    # Add custom head for classification\n",
    "    x = layers.GlobalAveragePooling2D()(backbone)\n",
    "    x = layers.Dense(128, activation='softmax')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='ResNet50')\n",
    "    return model\n",
    "\n",
    "model = ResNet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4049 - loss: 1.8342\n",
      "Epoch 2/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.3994 - loss: 1.8493\n",
      "Epoch 3/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4081 - loss: 1.8116\n",
      "Epoch 4/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.3988 - loss: 1.8161\n",
      "Epoch 5/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.3987 - loss: 1.8359\n",
      "Epoch 6/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4033 - loss: 1.8143\n",
      "Epoch 7/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4102 - loss: 1.7868\n",
      "Epoch 8/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4419 - loss: 1.7275\n",
      "Epoch 9/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4177 - loss: 1.7590\n",
      "Epoch 10/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4141 - loss: 1.7717\n",
      "Epoch 11/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4213 - loss: 1.7884\n",
      "Epoch 12/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4063 - loss: 1.8062\n",
      "Epoch 13/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4189 - loss: 1.7443\n",
      "Epoch 14/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4393 - loss: 1.7497\n",
      "Epoch 15/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4114 - loss: 1.7749\n",
      "Epoch 16/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4515 - loss: 1.7037\n",
      "Epoch 17/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4478 - loss: 1.7096\n",
      "Epoch 18/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4494 - loss: 1.6914\n",
      "Epoch 19/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4529 - loss: 1.6902\n",
      "Epoch 20/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4364 - loss: 1.7536\n",
      "Epoch 21/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4208 - loss: 1.7890\n",
      "Epoch 22/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4272 - loss: 1.7144\n",
      "Epoch 23/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4386 - loss: 1.7383\n",
      "Epoch 24/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4580 - loss: 1.6807\n",
      "Epoch 25/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4669 - loss: 1.6862\n",
      "Epoch 26/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4386 - loss: 1.7340\n",
      "Epoch 27/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4556 - loss: 1.6889\n",
      "Epoch 28/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4717 - loss: 1.6735\n",
      "Epoch 29/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4704 - loss: 1.6757\n",
      "Epoch 30/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4682 - loss: 1.6471\n",
      "Epoch 31/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4698 - loss: 1.6491\n",
      "Epoch 32/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4610 - loss: 1.6631\n",
      "Epoch 33/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4857 - loss: 1.6089\n",
      "Epoch 34/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4597 - loss: 1.6766\n",
      "Epoch 35/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4836 - loss: 1.5920\n",
      "Epoch 36/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5061 - loss: 1.5788\n",
      "Epoch 37/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4786 - loss: 1.6117\n",
      "Epoch 38/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4778 - loss: 1.6108\n",
      "Epoch 39/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5011 - loss: 1.5937\n",
      "Epoch 40/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4679 - loss: 1.6430\n",
      "Epoch 41/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4606 - loss: 1.6568\n",
      "Epoch 42/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4560 - loss: 1.6896\n",
      "Epoch 43/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4850 - loss: 1.6068\n",
      "Epoch 44/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4697 - loss: 1.6128\n",
      "Epoch 45/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4986 - loss: 1.5983\n",
      "Epoch 46/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4899 - loss: 1.5863\n",
      "Epoch 47/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4796 - loss: 1.5916\n",
      "Epoch 48/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4805 - loss: 1.5851\n",
      "Epoch 49/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5046 - loss: 1.5589\n",
      "Epoch 50/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4687 - loss: 1.5901\n",
      "Epoch 51/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4795 - loss: 1.5488\n",
      "Epoch 52/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5207 - loss: 1.5432\n",
      "Epoch 53/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4886 - loss: 1.5445\n",
      "Epoch 54/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4985 - loss: 1.5426\n",
      "Epoch 55/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5096 - loss: 1.5228\n",
      "Epoch 56/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.4926 - loss: 1.5607\n",
      "Epoch 57/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5051 - loss: 1.5304\n",
      "Epoch 58/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4819 - loss: 1.5638\n",
      "Epoch 59/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5136 - loss: 1.4871\n",
      "Epoch 60/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5076 - loss: 1.4926\n",
      "Epoch 61/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5114 - loss: 1.4887\n",
      "Epoch 62/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4848 - loss: 1.5256\n",
      "Epoch 63/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5144 - loss: 1.4937\n",
      "Epoch 64/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5080 - loss: 1.5032\n",
      "Epoch 65/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5023 - loss: 1.5323\n",
      "Epoch 66/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5160 - loss: 1.4969\n",
      "Epoch 67/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5237 - loss: 1.4383\n",
      "Epoch 68/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5483 - loss: 1.3982\n",
      "Epoch 69/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5146 - loss: 1.4988\n",
      "Epoch 70/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5345 - loss: 1.4157\n",
      "Epoch 71/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5067 - loss: 1.5349\n",
      "Epoch 72/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5218 - loss: 1.4859\n",
      "Epoch 73/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5087 - loss: 1.4974\n",
      "Epoch 74/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4847 - loss: 1.5256\n",
      "Epoch 75/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5284 - loss: 1.4114\n",
      "Epoch 76/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5336 - loss: 1.4127\n",
      "Epoch 77/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5244 - loss: 1.4442\n",
      "Epoch 78/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5081 - loss: 1.4945\n",
      "Epoch 79/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5042 - loss: 1.4734\n",
      "Epoch 80/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5042 - loss: 1.4783\n",
      "Epoch 81/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5473 - loss: 1.4278\n",
      "Epoch 82/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5218 - loss: 1.4220\n",
      "Epoch 83/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5332 - loss: 1.4413\n",
      "Epoch 84/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5307 - loss: 1.4220\n",
      "Epoch 85/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5485 - loss: 1.3671\n",
      "Epoch 86/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5700 - loss: 1.3283\n",
      "Epoch 87/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5290 - loss: 1.3921\n",
      "Epoch 88/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5533 - loss: 1.3542\n",
      "Epoch 89/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5435 - loss: 1.3472\n",
      "Epoch 90/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5543 - loss: 1.3490\n",
      "Epoch 91/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5589 - loss: 1.3071\n",
      "Epoch 92/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5633 - loss: 1.3170\n",
      "Epoch 93/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5573 - loss: 1.3156\n",
      "Epoch 94/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5532 - loss: 1.3529\n",
      "Epoch 95/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5937 - loss: 1.2709\n",
      "Epoch 96/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5781 - loss: 1.2611\n",
      "Epoch 97/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5789 - loss: 1.2687\n",
      "Epoch 98/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5446 - loss: 1.3449\n",
      "Epoch 99/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5420 - loss: 1.3271\n",
      "Epoch 100/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5623 - loss: 1.2932\n",
      "Epoch 101/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5696 - loss: 1.2943\n",
      "Epoch 102/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5571 - loss: 1.3521\n",
      "Epoch 103/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5788 - loss: 1.2621\n",
      "Epoch 104/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5868 - loss: 1.2492\n",
      "Epoch 105/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5691 - loss: 1.2703\n",
      "Epoch 106/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5996 - loss: 1.2275\n",
      "Epoch 107/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6103 - loss: 1.2073\n",
      "Epoch 108/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6106 - loss: 1.2029\n",
      "Epoch 109/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5862 - loss: 1.2145\n",
      "Epoch 110/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5688 - loss: 1.2784\n",
      "Epoch 111/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5722 - loss: 1.2583\n",
      "Epoch 112/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6067 - loss: 1.1876\n",
      "Epoch 113/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5720 - loss: 1.2675\n",
      "Epoch 114/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5543 - loss: 1.2631\n",
      "Epoch 115/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5488 - loss: 1.3727\n",
      "Epoch 116/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5869 - loss: 1.3034\n",
      "Epoch 117/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5637 - loss: 1.3709\n",
      "Epoch 118/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5640 - loss: 1.3005\n",
      "Epoch 119/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5710 - loss: 1.3791\n",
      "Epoch 120/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5851 - loss: 1.3333\n",
      "Epoch 121/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5577 - loss: 1.3382\n",
      "Epoch 122/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5839 - loss: 1.2769\n",
      "Epoch 123/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5985 - loss: 1.2689\n",
      "Epoch 124/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6101 - loss: 1.1848\n",
      "Epoch 125/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5927 - loss: 1.2218\n",
      "Epoch 126/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6082 - loss: 1.2227\n",
      "Epoch 127/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.5882 - loss: 1.2090\n",
      "Epoch 128/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6247 - loss: 1.1389\n",
      "Epoch 129/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6064 - loss: 1.1837\n",
      "Epoch 130/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6462 - loss: 1.1154\n",
      "Epoch 131/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6419 - loss: 1.1144\n",
      "Epoch 132/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6247 - loss: 1.1265\n",
      "Epoch 133/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6429 - loss: 1.1124\n",
      "Epoch 134/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6511 - loss: 1.1085\n",
      "Epoch 135/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6554 - loss: 1.0712\n",
      "Epoch 136/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6515 - loss: 1.1085\n",
      "Epoch 137/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6498 - loss: 1.0895\n",
      "Epoch 138/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6856 - loss: 1.0048\n",
      "Epoch 139/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6493 - loss: 1.0353\n",
      "Epoch 140/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6758 - loss: 0.9977\n",
      "Epoch 141/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6770 - loss: 0.9994\n",
      "Epoch 142/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6232 - loss: 1.1224\n",
      "Epoch 143/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6182 - loss: 1.1780\n",
      "Epoch 144/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6759 - loss: 0.9944\n",
      "Epoch 145/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6975 - loss: 0.9676\n",
      "Epoch 146/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6837 - loss: 1.0192\n",
      "Epoch 147/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6562 - loss: 1.0263\n",
      "Epoch 148/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6958 - loss: 0.9567\n",
      "Epoch 149/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.6833 - loss: 0.9768\n",
      "Epoch 150/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.7111 - loss: 0.9518\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, target, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.7764706 , 0.75686276, 0.73333335],\n",
       "         [0.3882353 , 0.36862746, 0.3529412 ],\n",
       "         [0.26666668, 0.24705882, 0.24705882],\n",
       "         ...,\n",
       "         [0.26666668, 0.25882354, 0.26666668],\n",
       "         [0.26666668, 0.25882354, 0.27058825],\n",
       "         [0.27058825, 0.2627451 , 0.2784314 ]],\n",
       "\n",
       "        [[0.7764706 , 0.7607843 , 0.7372549 ],\n",
       "         [0.21568628, 0.20392157, 0.19215687],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.00392157]],\n",
       "\n",
       "        [[0.7764706 , 0.7647059 , 0.7372549 ],\n",
       "         [0.23137255, 0.21960784, 0.2       ],\n",
       "         [0.01960784, 0.00392157, 0.00392157],\n",
       "         ...,\n",
       "         [0.00784314, 0.        , 0.00784314],\n",
       "         [0.01176471, 0.00392157, 0.01568628],\n",
       "         [0.01568628, 0.00784314, 0.02352941]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.76862746, 0.77254903, 0.7411765 ],\n",
       "         [0.21568628, 0.21568628, 0.20392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00784314, 0.        , 0.01568628],\n",
       "         [0.00784314, 0.        , 0.02352941],\n",
       "         [0.01176471, 0.        , 0.02745098]],\n",
       "\n",
       "        [[0.76862746, 0.77254903, 0.7411765 ],\n",
       "         [0.21568628, 0.21568628, 0.20392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.01568628],\n",
       "         [0.00392157, 0.        , 0.02352941],\n",
       "         [0.00784314, 0.00392157, 0.02745098]],\n",
       "\n",
       "        [[0.76862746, 0.77254903, 0.74509805],\n",
       "         [0.21960784, 0.21960784, 0.20392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.01568628, 0.01176471, 0.02352941],\n",
       "         [0.00784314, 0.00392157, 0.02745098],\n",
       "         [0.00392157, 0.        , 0.02352941]]],\n",
       "\n",
       "\n",
       "       [[[0.01960784, 0.00392157, 0.00784314],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.12156863, 0.09411765, 0.14117648],\n",
       "         [0.2784314 , 0.25490198, 0.29803923],\n",
       "         [0.38039216, 0.35686275, 0.3882353 ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.20392157, 0.18431373, 0.23921569],\n",
       "         [0.56078434, 0.5254902 , 0.5764706 ],\n",
       "         [0.5686275 , 0.50980395, 0.53333336],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.00784314, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.01176471, 0.        , 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.00784314, 0.00392157],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.00784314, 0.        , 0.        ],\n",
       "         [0.00392157, 0.00784314, 0.00392157],\n",
       "         [0.        , 0.01176471, 0.00784314],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314]]],\n",
       "\n",
       "\n",
       "       [[[0.0627451 , 0.06666667, 0.07450981],\n",
       "         [0.02352941, 0.05490196, 0.10588235],\n",
       "         [0.41568628, 0.4745098 , 0.53333336],\n",
       "         ...,\n",
       "         [0.85490197, 0.85490197, 0.85490197],\n",
       "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
       "         [0.3019608 , 0.3019608 , 0.3019608 ]],\n",
       "\n",
       "        [[0.06666667, 0.0627451 , 0.07450981],\n",
       "         [0.05490196, 0.07843138, 0.10980392],\n",
       "         [0.34509805, 0.4       , 0.44705883],\n",
       "         ...,\n",
       "         [0.85490197, 0.85490197, 0.85490197],\n",
       "         [0.90588236, 0.90588236, 0.90588236],\n",
       "         [0.3019608 , 0.3019608 , 0.3019608 ]],\n",
       "\n",
       "        [[0.07843138, 0.06666667, 0.07843138],\n",
       "         [0.05490196, 0.06666667, 0.07058824],\n",
       "         [0.38039216, 0.42352942, 0.41568628],\n",
       "         ...,\n",
       "         [0.85490197, 0.85490197, 0.85490197],\n",
       "         [0.90588236, 0.90588236, 0.90588236],\n",
       "         [0.29411766, 0.29411766, 0.29411766]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.07450981, 0.07058824, 0.03529412],\n",
       "         [0.02745098, 0.04313726, 0.01568628],\n",
       "         [0.42352942, 0.4627451 , 0.42352942],\n",
       "         ...,\n",
       "         [0.72156864, 0.7254902 , 0.7019608 ],\n",
       "         [0.78039217, 0.77254903, 0.7647059 ],\n",
       "         [0.2901961 , 0.27058825, 0.28627452]],\n",
       "\n",
       "        [[0.03529412, 0.03921569, 0.02745098],\n",
       "         [0.03921569, 0.04313726, 0.03529412],\n",
       "         [0.03137255, 0.03529412, 0.02745098],\n",
       "         ...,\n",
       "         [0.03921569, 0.03529412, 0.02352941],\n",
       "         [0.03529412, 0.02745098, 0.01960784],\n",
       "         [0.04313726, 0.02352941, 0.03529412]],\n",
       "\n",
       "        [[0.00392157, 0.00784314, 0.01960784],\n",
       "         [0.01176471, 0.00392157, 0.02352941],\n",
       "         [0.02352941, 0.00392157, 0.02352941],\n",
       "         ...,\n",
       "         [0.00784314, 0.00392157, 0.        ],\n",
       "         [0.01176471, 0.00392157, 0.00392157],\n",
       "         [0.01568628, 0.00784314, 0.01568628]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.01176471, 0.01568628, 0.01960784],\n",
       "         [0.01568628, 0.01960784, 0.02352941],\n",
       "         [0.00392157, 0.00784314, 0.01176471],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.01960784, 0.02352941, 0.03137255],\n",
       "         [0.02745098, 0.03137255, 0.03921569],\n",
       "         [0.01568628, 0.01960784, 0.02745098],\n",
       "         ...,\n",
       "         [0.00784314, 0.00784314, 0.01568628],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.04705882, 0.04705882, 0.05490196],\n",
       "         [0.00392157, 0.00392157, 0.01176471],\n",
       "         [0.03921569, 0.03921569, 0.04705882],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.01568628],\n",
       "         [0.        , 0.        , 0.01568628],\n",
       "         [0.        , 0.        , 0.01568628]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.02745098, 0.02745098, 0.02745098],\n",
       "         [0.01176471, 0.01176471, 0.01176471],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.00784314],\n",
       "         [0.        , 0.        , 0.00784314],\n",
       "         [0.        , 0.        , 0.00784314]],\n",
       "\n",
       "        [[0.21568628, 0.21568628, 0.20784314],\n",
       "         [0.07843138, 0.07843138, 0.07058824],\n",
       "         [0.13333334, 0.13333334, 0.12941177],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.01176471, 0.        , 0.        ],\n",
       "         [0.01176471, 0.        , 0.        ],\n",
       "         [0.01176471, 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ]],\n",
       "\n",
       "        [[0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         [0.00392157, 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ],\n",
       "         [0.        , 0.00392157, 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.6392157 , 0.65882355, 0.68235296],\n",
       "         [0.6509804 , 0.68235296, 0.6862745 ],\n",
       "         [0.6666667 , 0.6784314 , 0.6901961 ],\n",
       "         ...,\n",
       "         [0.6666667 , 0.69803923, 0.6901961 ],\n",
       "         [0.6666667 , 0.6862745 , 0.69411767],\n",
       "         [0.654902  , 0.6784314 , 0.69411767]],\n",
       "\n",
       "        [[0.6509804 , 0.67058825, 0.68235296],\n",
       "         [0.64705884, 0.68235296, 0.6745098 ],\n",
       "         [0.6627451 , 0.68235296, 0.69803923],\n",
       "         ...,\n",
       "         [0.65882355, 0.6862745 , 0.6901961 ],\n",
       "         [0.6666667 , 0.6901961 , 0.69411767],\n",
       "         [0.64705884, 0.6784314 , 0.6862745 ]],\n",
       "\n",
       "        [[0.6666667 , 0.6901961 , 0.69411767],\n",
       "         [0.6509804 , 0.6784314 , 0.6784314 ],\n",
       "         [0.65882355, 0.6784314 , 0.69411767],\n",
       "         ...,\n",
       "         [0.6509804 , 0.68235296, 0.6901961 ],\n",
       "         [0.6509804 , 0.6784314 , 0.6862745 ],\n",
       "         [0.6509804 , 0.68235296, 0.6901961 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.69803923, 0.7176471 , 0.7058824 ],\n",
       "         [0.7176471 , 0.73333335, 0.72156864],\n",
       "         [0.7254902 , 0.74509805, 0.72156864],\n",
       "         ...,\n",
       "         [0.7058824 , 0.73333335, 0.70980394],\n",
       "         [0.72156864, 0.73333335, 0.7254902 ],\n",
       "         [0.72156864, 0.73333335, 0.7294118 ]],\n",
       "\n",
       "        [[0.7058824 , 0.7294118 , 0.7019608 ],\n",
       "         [0.7254902 , 0.73333335, 0.7254902 ],\n",
       "         [0.7254902 , 0.7372549 , 0.72156864],\n",
       "         ...,\n",
       "         [0.69803923, 0.7137255 , 0.69411767],\n",
       "         [0.7137255 , 0.73333335, 0.7176471 ],\n",
       "         [0.70980394, 0.7254902 , 0.7254902 ]],\n",
       "\n",
       "        [[0.69803923, 0.72156864, 0.69803923],\n",
       "         [0.7176471 , 0.7254902 , 0.72156864],\n",
       "         [0.70980394, 0.7254902 , 0.7058824 ],\n",
       "         ...,\n",
       "         [0.69411767, 0.7058824 , 0.7058824 ],\n",
       "         [0.7137255 , 0.7294118 , 0.7176471 ],\n",
       "         [0.72156864, 0.73333335, 0.7254902 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# test_image_dir = '테스트셋'  # 이미지 폴더 경로\n",
    "\n",
    "# # 이미지 읽기 및 전처리\n",
    "# test_images = []  # 리스트로 선언\n",
    "# for filename in os.listdir(test_image_dir):\n",
    "#     if filename.lower().endswith(('.jpg', '.png')):  # 확장자를 소문자로 변환 후 비교\n",
    "#         img_path = os.path.join(test_image_dir, filename)\n",
    "#         try:\n",
    "#             image = Image.open(img_path).convert('RGB').resize((256, 256))  # 이미지 크기 조정 및 RGB 변환\n",
    "#             image_array = img_to_array(image) / 255.0  # 이미지를 배열로 변환하고 정규화\n",
    "#             test_images.append(image_array)  # 리스트에 이미지 추가\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading image {filename}: {e}\")\n",
    "\n",
    "# # 이미지 데이터를 NumPy 배열로 변환\n",
    "# test_images = np.array(test_images)  # 리스트를 한 번에 NumPy 배열로 변환\n",
    "\n",
    "# test_data = test_images\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.7764706  0.75686276 0.73333335]\n",
      "   [0.3882353  0.36862746 0.3529412 ]\n",
      "   [0.26666668 0.24705882 0.24705882]\n",
      "   ...\n",
      "   [0.26666668 0.25882354 0.26666668]\n",
      "   [0.26666668 0.25882354 0.27058825]\n",
      "   [0.27058825 0.2627451  0.2784314 ]]\n",
      "\n",
      "  [[0.7764706  0.7607843  0.7372549 ]\n",
      "   [0.21568628 0.20392157 0.19215687]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.00392157]]\n",
      "\n",
      "  [[0.7764706  0.7647059  0.7372549 ]\n",
      "   [0.23137255 0.21960784 0.2       ]\n",
      "   [0.01960784 0.00392157 0.00392157]\n",
      "   ...\n",
      "   [0.00784314 0.         0.00784314]\n",
      "   [0.01176471 0.00392157 0.01568628]\n",
      "   [0.01568628 0.00784314 0.02352941]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.76862746 0.77254903 0.7411765 ]\n",
      "   [0.21568628 0.21568628 0.20392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.00784314 0.         0.01568628]\n",
      "   [0.00784314 0.         0.02352941]\n",
      "   [0.01176471 0.         0.02745098]]\n",
      "\n",
      "  [[0.76862746 0.77254903 0.7411765 ]\n",
      "   [0.21568628 0.21568628 0.20392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.01568628]\n",
      "   [0.00392157 0.         0.02352941]\n",
      "   [0.00784314 0.00392157 0.02745098]]\n",
      "\n",
      "  [[0.76862746 0.77254903 0.74509805]\n",
      "   [0.21960784 0.21960784 0.20392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.01568628 0.01176471 0.02352941]\n",
      "   [0.00784314 0.00392157 0.02745098]\n",
      "   [0.00392157 0.         0.02352941]]]\n",
      "\n",
      "\n",
      " [[[0.91764706 0.92156863 0.90588236]\n",
      "   [0.91764706 0.91764706 0.9137255 ]\n",
      "   [0.90588236 0.90588236 0.92156863]\n",
      "   ...\n",
      "   [0.91764706 0.91764706 0.91764706]\n",
      "   [0.91764706 0.91764706 0.91764706]\n",
      "   [0.92156863 0.92156863 0.92156863]]\n",
      "\n",
      "  [[0.91764706 0.92156863 0.9019608 ]\n",
      "   [0.9411765  0.9411765  0.93333334]\n",
      "   [0.9019608  0.8980392  0.9137255 ]\n",
      "   ...\n",
      "   [0.9098039  0.9098039  0.9098039 ]\n",
      "   [0.9098039  0.9098039  0.9098039 ]\n",
      "   [0.9137255  0.9137255  0.9137255 ]]\n",
      "\n",
      "  [[0.8039216  0.80784315 0.7882353 ]\n",
      "   [0.8784314  0.8784314  0.8745098 ]\n",
      "   [0.7882353  0.78431374 0.8       ]\n",
      "   ...\n",
      "   [0.9019608  0.9019608  0.9019608 ]\n",
      "   [0.9019608  0.9019608  0.9019608 ]\n",
      "   [0.90588236 0.90588236 0.90588236]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.18431373 0.2        0.23529412]\n",
      "   [0.06666667 0.07843138 0.10588235]\n",
      "   [0.07450981 0.10196079 0.12941177]\n",
      "   ...\n",
      "   [0.07058824 0.09019608 0.12941177]\n",
      "   [0.06666667 0.07843138 0.11764706]\n",
      "   [0.2        0.21960784 0.25882354]]\n",
      "\n",
      "  [[0.44313726 0.47843137 0.5137255 ]\n",
      "   [0.32941177 0.35686275 0.39215687]\n",
      "   [0.3529412  0.38431373 0.41568628]\n",
      "   ...\n",
      "   [0.3372549  0.36078432 0.40784314]\n",
      "   [0.3254902  0.3529412  0.39607844]\n",
      "   [0.4627451  0.49019608 0.53333336]]\n",
      "\n",
      "  [[0.1882353  0.22352941 0.25882354]\n",
      "   [0.07450981 0.10980392 0.14509805]\n",
      "   [0.09803922 0.13333334 0.16862746]\n",
      "   ...\n",
      "   [0.09803922 0.12941177 0.17254902]\n",
      "   [0.08235294 0.11372549 0.15686275]\n",
      "   [0.21568628 0.24705882 0.2901961 ]]]\n",
      "\n",
      "\n",
      " [[[0.01176471 0.01176471 0.01176471]\n",
      "   [0.01568628 0.01568628 0.01176471]\n",
      "   [0.00392157 0.00392157 0.00784314]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.01960784 0.01960784 0.02745098]\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.00784314 0.00784314 0.01568628]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.01568628 0.01568628 0.02352941]\n",
      "   [0.01176471 0.00784314 0.01176471]\n",
      "   [0.15294118 0.14509805 0.16078432]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.01176471 0.00392157 0.00784314]\n",
      "   [0.01176471 0.00392157 0.00784314]\n",
      "   [0.01176471 0.00784314 0.01176471]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00784314 0.00784314 0.00784314]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.01568628 0.01568628 0.01568628]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.1882353  0.1882353  0.1882353 ]\n",
      "   [0.02745098 0.02745098 0.02745098]\n",
      "   [0.18039216 0.18039216 0.18039216]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.00784314 0.00784314 0.00784314]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.00784314 0.00784314 0.00784314]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.19215687 0.19215687 0.19215687]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.18431373 0.18431373 0.18431373]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.01176471 0.01176471 0.01176471]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.01568628 0.01568628 0.01568628]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.00392157 0.00392157 0.00392157]\n",
      "   [0.01176471 0.01176471 0.01176471]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.19215687 0.19215687 0.19215687]\n",
      "   [0.03137255 0.03137255 0.03137255]\n",
      "   [0.18431373 0.18431373 0.18431373]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "test_image_dir = '테스트셋'  # 이미지 폴더 경로\n",
    "\n",
    "# 이미지 읽기 및 전처리\n",
    "test_images = []  # 리스트로 선언\n",
    "\n",
    "# 파일 목록을 가져오고 숫자 순서대로 정렬\n",
    "file_list = sorted(os.listdir(test_image_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "for filename in file_list:\n",
    "    if filename.lower().endswith(('.jpg', '.png')):  # 확장자를 소문자로 변환 후 비교\n",
    "        img_path = os.path.join(test_image_dir, filename)\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB').resize((256, 256))  # 이미지 크기 조정 및 RGB 변환\n",
    "            image_array = img_to_array(image) / 255.0  # 이미지를 배열로 변환하고 정규화\n",
    "            test_images.append(image_array)  # 리스트에 이미지 추가\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {filename}: {e}\")\n",
    "\n",
    "# 이미지 데이터를 NumPy 배열로 변환\n",
    "test_images = np.array(test_images)  # 리스트를 한 번에 NumPy 배열로 변환\n",
    "\n",
    "test_data = test_images\n",
    "print(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[7 6 8 6 3 2 0 2 3 3 2 3 3 0 2 0 8 3 8 8 1 2 0 3 3 7 3 3 3 3 2 1 3 0 3 3 2\n",
      " 6 1 6 4 8 8 3 0 3 1 0 3 0 0 0 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "# binary_predictions = (predictions > 0.5).astype(int)\n",
    "class_predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(class_predictions)\n",
    "len(class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/FIshing_vessel/resnet50.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(test_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_loss, test_accuracy \u001b[39m=\u001b[39m test_history\n\u001b[1;32m      <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest loss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m.8f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optree/ops.py:747\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m leaves, treespec \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    746\u001b[0m flat_args \u001b[39m=\u001b[39m [leaves] \u001b[39m+\u001b[39m [treespec\u001b[39m.\u001b[39mflatten_up_to(r) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rests]\n\u001b[0;32m--> 747\u001b[0m \u001b[39mreturn\u001b[39;00m treespec\u001b[39m.\u001b[39;49munflatten(\u001b[39mmap\u001b[39;49m(func, \u001b[39m*\u001b[39;49mflat_args))\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "test_history = model.evaluate(test_data)\n",
    "test_loss, test_accuracy = test_history\n",
    "\n",
    "print(f\"Test loss: {test_loss:.8f}\")\n",
    "print(f\"Test accuracy: {test_accuracy *  100.:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1581, 53]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/elicer/FIshing_vessel/resnet50.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[0;32m----> <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m report \u001b[39m=\u001b[39m classification_report(target, class_predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mClassification Report:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://xfattwwmtmdhcgbc.tunnel-pt.elice.io/home/elicer/FIshing_vessel/resnet50.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(report)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2626\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2492\u001b[0m     {\n\u001b[1;32m   2493\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2517\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2518\u001b[0m ):\n\u001b[1;32m   2519\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \n\u001b[1;32m   2521\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2624\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2626\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2628\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2629\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[39mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m    104\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1581, 53]"
     ]
    }
   ],
   "source": [
    "# classification report를 출력하려면 실제 레이블값 필요함\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# report = classification_report(, class_predictions)\n",
    "# print('Classification Report:')\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
